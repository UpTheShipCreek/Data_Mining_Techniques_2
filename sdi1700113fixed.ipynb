{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f9d13d",
   "metadata": {
    "id": "e4f9d13d"
   },
   "source": [
    "# # <div style=\"text-align:center\"> Τεχνικές Εξόρυξης Δεδομένων: 2η Άσκηση  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d05e85",
   "metadata": {
    "id": "18d05e85"
   },
   "source": [
    "### <div style=\"text-align:center\">  Παναγιώτοπουλος Γεώργιος **1115201700113** </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1fa2df",
   "metadata": {
    "id": "ac1fa2df"
   },
   "source": [
    "Αρχικά θα εισάγετε όλο το αρχείο σε ένα dataframe και θα μελετήσετε αν υπάρχουν τιμές Nan\n",
    "στις στήλες ώστε να αφαιρέσετε αυτές τις γραμμες από το dataframe. Στην συνέχεια θα γράψετε\n",
    "την κατάλληλες εντολές σε python για να απαντήσετε στα παρακάτω ζητούμενα. Τι περισσότερες\n",
    "φορές οι απαντήσει θα δίνονται με ένα γράφημα και μπορείτε να χρησιμοποιήσετε όποια python\n",
    "βιβλιοθήκη θέλετε για το σκοπό αυτό."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5581f96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5581f96",
    "outputId": "e9966bcc-fd7b-4365-aace-5751283e02a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bookId            52478 non-null  object \n",
      " 1   title             52478 non-null  object \n",
      " 2   series            23470 non-null  object \n",
      " 3   author            52478 non-null  object \n",
      " 4   rating            52478 non-null  float64\n",
      " 5   description       51140 non-null  object \n",
      " 6   language          48672 non-null  object \n",
      " 7   isbn              52478 non-null  object \n",
      " 8   genres            52478 non-null  object \n",
      " 9   characters        52478 non-null  object \n",
      " 10  bookFormat        51005 non-null  object \n",
      " 11  edition           4955 non-null   object \n",
      " 12  pages             50131 non-null  object \n",
      " 13  publisher         48782 non-null  object \n",
      " 14  publishDate       51598 non-null  object \n",
      " 15  firstPublishDate  31152 non-null  object \n",
      " 16  awards            52478 non-null  object \n",
      " 17  numRatings        52478 non-null  int64  \n",
      " 18  ratingsByStars    52478 non-null  object \n",
      " 19  likedPercent      51856 non-null  float64\n",
      " 20  setting           52478 non-null  object \n",
      " 21  coverImg          51873 non-null  object \n",
      " 22  bbeScore          52478 non-null  int64  \n",
      " 23  bbeVotes          52478 non-null  int64  \n",
      " 24  price             38113 non-null  object \n",
      "dtypes: float64(2), int64(3), object(20)\n",
      "memory usage: 10.0+ MB\n",
      "Number of null values in 'title' column before cleaning: 29008\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/')\n",
    "\n",
    "#df = pd.read_csv('./books_1.Best_Books_Ever.csv', nrows=50)\n",
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/books_1.Best_Books_Ever.csv')\n",
    "df.info(verbose=True)\n",
    "print(\"Number of null values in 'title' column before cleaning:\", df['series'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c710bbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c710bbf",
    "outputId": "3e2cbc5f-9305-4959-a4fd-f796588a5430",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27121 entries, 0 to 27120\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bookId            27121 non-null  object \n",
      " 1   title             27121 non-null  object \n",
      " 2   series            27121 non-null  object \n",
      " 3   author            27121 non-null  object \n",
      " 4   rating            27121 non-null  float64\n",
      " 5   description       27121 non-null  object \n",
      " 6   language          27121 non-null  object \n",
      " 7   isbn              27121 non-null  object \n",
      " 8   genres            27121 non-null  object \n",
      " 9   characters        27121 non-null  object \n",
      " 10  bookFormat        27121 non-null  object \n",
      " 11  edition           27121 non-null  object \n",
      " 12  pages             27121 non-null  object \n",
      " 13  publisher         27121 non-null  object \n",
      " 14  publishDate       27121 non-null  object \n",
      " 15  firstPublishDate  27121 non-null  object \n",
      " 16  awards            27121 non-null  object \n",
      " 17  numRatings        27121 non-null  int64  \n",
      " 18  ratingsByStars    27121 non-null  object \n",
      " 19  likedPercent      27121 non-null  float64\n",
      " 20  setting           27121 non-null  object \n",
      " 21  coverImg          27121 non-null  object \n",
      " 22  bbeScore          27121 non-null  int64  \n",
      " 23  bbeVotes          27121 non-null  int64  \n",
      " 24  price             27121 non-null  float64\n",
      "dtypes: float64(3), int64(3), object(19)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Μπορούμε να βάλουμε τo median price σε όσα βιβλία δεν εχουν κάποια τίμη\n",
    "import re\n",
    "def fix_double_dots(string): #Some of the prices have three `.` for some reason\n",
    "    pattern = r'^(\\w+)\\.(\\w+)\\.(\\w+)$'\n",
    "    match = re.match(pattern, string)\n",
    "    if match:\n",
    "        return match.group(1) + match.group(2) + '.' + match.group(3)\n",
    "    else:\n",
    "        return string\n",
    "    \n",
    "prices = []\n",
    "for i in range(len(df.index)):\n",
    "    if isinstance(df['price'][i],str):\n",
    "        price = fix_double_dots(df['price'][i])\n",
    "    else:\n",
    "        price = df['price'][i]\n",
    "    prices.append(float(price))      \n",
    "df['price'] = prices\n",
    "price_median = df['price'].median()\n",
    "df['price'].fillna(price_median, inplace=True)\n",
    "\n",
    "# Επίσης μπορόυμε να υποθέσουμε ότι για τα βιβλία που δεν αναγράφεται edition,ισχύει το Standard edition\n",
    "df['edition'].fillna('Standard Edition',inplace=True)\n",
    "\n",
    "# Και ότι για όσα δεν αναγράφεται Series, ΄ότι είναι Standalone\n",
    "df['series'].fillna('Standalone',inplace=True)\n",
    "\n",
    "df_clean = df.dropna().reset_index(drop=True)\n",
    "df_clean.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58bcfd3",
   "metadata": {
    "id": "a58bcfd3"
   },
   "source": [
    "## 1) Προεπεξεργασία (10%) \n",
    "Παρατηρήστε την στήλη ratingsByStars, περιέχει 5 τιμές χωρισμένες με κόμματα , χωρίστε τις\n",
    "τιμές αυτές και προσθέστε στο dataframe ξεχωριστά τα ratings, δηλαδή ratingStar5, ratingStar4,\n",
    "ratingStar3 κτλ.\n",
    "Επίσης η στήλη genres περιέχει για κάθε βιβλίο περισσότερα από ένα genre (είδος).\n",
    "Δημιουργήστε μία νέα στήλη (ονομάστε την genreSingle) και βάλτε μόνο το πρώτο genre από\n",
    "όλα τα genres που συναντάμε σε κάθε γραμμή. (πχ ['Fantasy', 'Young Adult', 'Fiction', 'Magic',\n",
    "'Childrens', 'Adventure', 'Audiobook', 'Middle Grade', 'Classics', 'Science Fiction Fantasy'] -> η\n",
    "νέα στήλη θα έχει το 'Fantasy' ) deleting books without any genre information.\n",
    "Χρησιμοποιήστε την στήλη publishDate και δημιουργήστε μία νέα στήλη με το έτος έκδοσης κάθε\n",
    "βιβλίου (μπορείτε να χρησιμοποιήστε την μέθοδο to_datetime() που παρέχει το pandas ή ότι\n",
    "άλλο θέλετε) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9eed4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b9eed4a",
    "outputId": "33dd57bc-a11c-45f4-b43f-4dfad9ea8b12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: dateparser in /usr/local/lib/python3.10/dist-packages (1.1.8)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser) (2.8.2)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser) (2022.7.1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser) (2022.10.31)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser) (4.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dateparser) (1.16.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->dateparser) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->dateparser) (2023.3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26889 entries, 0 to 26888\n",
      "Data columns (total 32 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bookId            26889 non-null  object \n",
      " 1   title             26889 non-null  object \n",
      " 2   series            26889 non-null  object \n",
      " 3   author            26889 non-null  object \n",
      " 4   rating            26889 non-null  float64\n",
      " 5   description       26889 non-null  object \n",
      " 6   language          26889 non-null  object \n",
      " 7   isbn              26889 non-null  object \n",
      " 8   genres            26889 non-null  object \n",
      " 9   characters        26889 non-null  object \n",
      " 10  bookFormat        26889 non-null  object \n",
      " 11  edition           26889 non-null  object \n",
      " 12  pages             26889 non-null  object \n",
      " 13  publisher         26889 non-null  object \n",
      " 14  publishDate       26889 non-null  object \n",
      " 15  firstPublishDate  26889 non-null  object \n",
      " 16  awards            26889 non-null  object \n",
      " 17  numRatings        26889 non-null  int64  \n",
      " 18  ratingsByStars    26889 non-null  object \n",
      " 19  likedPercent      26889 non-null  float64\n",
      " 20  setting           26889 non-null  object \n",
      " 21  coverImg          26889 non-null  object \n",
      " 22  bbeScore          26889 non-null  int64  \n",
      " 23  bbeVotes          26889 non-null  int64  \n",
      " 24  price             26889 non-null  float64\n",
      " 25  ratingStar5       26889 non-null  object \n",
      " 26  ratingStar4       26889 non-null  object \n",
      " 27  ratingStar3       26889 non-null  object \n",
      " 28  ratingStar2       26889 non-null  object \n",
      " 29  ratingStar1       26889 non-null  object \n",
      " 30  genreSingle       26889 non-null  object \n",
      " 31  publishYear       26889 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(25)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "!pip install dateparser\n",
    "import dateparser\n",
    "\n",
    "#rows = len(df_clean.index)\n",
    "\n",
    "# Useful function for getting rid of trash symbols\n",
    "def remove_trash_symbols(string,symbols):\n",
    "    for symbol in symbols:\n",
    "            string = string.replace(symbol, \"\")\n",
    "    return string\n",
    "\n",
    "# Seperating rating entries\n",
    "symbols_to_remove = \"[]''\"\n",
    "clean = []\n",
    "reformatted = []\n",
    "for i in range(len(df_clean.index)): # For the ratings of every book\n",
    "    entry = df_clean['ratingsByStars'][i]\n",
    "    if(entry == \"[]\"): # some completely empty entries for some reason exist\n",
    "        entry = \"[0,0,0,0,0]\"\n",
    "    formatted = list(entry.split(\",\")) # split the string in the comas\n",
    "    for rating in formatted: # and for every element of the broken form ['1593642 left\n",
    "        string_left = remove_trash_symbols(rating,symbols_to_remove)\n",
    "        clean.append(string_left)\n",
    "\n",
    "reformatted = np.array(clean).reshape(len(df_clean.index),5)\n",
    "\n",
    "# Adding the rows of the reformatted array into the dataframe\n",
    "df_clean['ratingStar5'] = reformatted[:,0]\n",
    "df_clean['ratingStar4'] = reformatted[:,1]\n",
    "df_clean['ratingStar3'] = reformatted[:,2]\n",
    "df_clean['ratingStar2'] = reformatted[:,3]\n",
    "df_clean['ratingStar1'] = reformatted[:,4]\n",
    "\n",
    "# Seperating genre\n",
    "first_genre = []\n",
    "for i in range(len(df_clean.index)): # For the ratings of every book\n",
    "    entry = df_clean['genres'][i]\n",
    "    first_genre.append(remove_trash_symbols(entry.split(',')[0],symbols_to_remove))\n",
    "# Adding the new main genre column\n",
    "df_clean['genreSingle'] = first_genre\n",
    "\n",
    "years = []\n",
    "for date in df_clean['publishDate']:\n",
    "    parsed_date = dateparser.parse(date)\n",
    "    if parsed_date is not None:\n",
    "        years.append(parsed_date.year)\n",
    "    else:\n",
    "        years.append(None) \n",
    "df_clean['publishYear'] = years\n",
    "\n",
    "df_clean = df_clean.dropna().reset_index(drop=True)\n",
    "df_clean.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cac866",
   "metadata": {
    "id": "26cac866"
   },
   "source": [
    "## 2) Ερωτήματα για μελέτη των δεδομένων - απαντήστε σε 5 από τα παρακάτω (20%)\n",
    "1. Κατασκευάστε το ιστόγραμμα των ratings στο σύνολο δεδομένων (χρησιμοποιήστε την\n",
    "στήλη rating)\n",
    "2. Ποιά είναι τα 10 βιβλία με τις περισσότερες σελίδες.\n",
    "3. Ποιά είναι τα 10 βιβλία με τα περισσότερα 5-αστέρια (χρησιμοποιήστε μόνο τα βιβλία που\n",
    "έχουν λάβει πάνω από 10.000 5-star ratings από τη στήλη ratingStar5) .\n",
    "4. Ποιές είναι οι πιο συχνές λέξεις στους τίτλους των βιβλίων (αφού αφαιρεθούν τα stop\n",
    "words)\n",
    "5. Ποιοι είναι οι 10 συγγραφεις με τα περισσότερα βιβλία\n",
    "6. Ποιοι είναι οι 10 συγγραφείς με τις περισσότερες κριτικές (χρησιμοποιήστε την στήλη\n",
    "numRatings).\n",
    "7. Κατατάξτε του συγγραφείς με βάση τα βιβλία τους ανά έτος.\n",
    "8. Ποιές είναι οι πιο συχνές γλώσσες που έχουν γραφτεί τα βιβλία στα δεδομένα σας\n",
    "9. Ποιοί είναι οι 10 εκδότες που έχουν εκδώσει τα περισσότερα βιβλία.\n",
    "10. Έχουν τα βιβλία με τις περισσότερες σελίδες (πχ περισσότερες από 1000 pages)\n",
    "υψηλότερα ratings ?\n",
    "11. Συγκεντρώστε σε ένα γράφημα η σε ένα πίνακα όλα τα μοναδικά είδη βιβλίων (genres).\n",
    "Ποιά είναι τα πιο συχνά genres; Το ίδιο και για τα awards.\n",
    "12. Φτιάξτε τα wordclouds για τη στήλη description. Σε αυτό το ερώτημα αφαιρέστε τα stop\n",
    "words, πειραματιστείτε με τις παραμέτρους του wordcloud και εντοπίστε τις πιο\n",
    "χαρακτηριστικές λέξεις που χρησιμοποιούνται στα βιβλία του συνόλου των δεδομένων\n",
    "σας.\n",
    "13. Πόσα βιβλία εκδίδονται ανά έτος ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20fd4406",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fd4406",
    "outputId": "941dfdd1-6231-4adb-8757-fae551eaa0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with most pages: \n",
      " 11961                        7506252-are-you-kidding-me\n",
      "14779                   591965.The_Madwoman_of_Chaillot\n",
      "16039                                    875775.Mission\n",
      "12187                       131094.Millroy_the_Magician\n",
      "18666                                      2581254-halo\n",
      "16150    10394216-the-complete-works-of-charles-dickens\n",
      "16265                          10168286-the-village-wit\n",
      "9482                       16312.One_Two_Buckle_My_Shoe\n",
      "18514                         121646.Murder_in_the_Mews\n",
      "12052                      7058894-12-stocking-stuffers\n",
      "Name: bookId, dtype: object\n",
      "Books with most 5 star ratings: \n",
      " 11063            15747245-close-your-eyes-and-see\n",
      "15460                        2338189.Zany_Hijinx_\n",
      "10976    12813058-lost-souls---the-cube-of-asgard\n",
      "11021              13560868-the-language-of-light\n",
      "13159        14643361-telling-time-by-the-shadows\n",
      "13790                        2583110-plural-loves\n",
      "11127                            3454581-the-list\n",
      "11167                   17455034-sign-of-the-time\n",
      "11176           14535907-jesus-and-moses-in-india\n",
      "15279                       1608094.Nuclear_Peace\n",
      "Name: bookId, dtype: object\n",
      "Authors with most books: \n",
      " author\n",
      "Agatha Christie                       68\n",
      "Terry Pratchett                       43\n",
      "Nora Roberts (Goodreads Author)       41\n",
      "Stephen King (Goodreads Author)       40\n",
      "Enid Blyton                           40\n",
      "Karen Kingsbury (Goodreads Author)    36\n",
      "Dean Koontz (Goodreads Author)        36\n",
      "P.G. Wodehouse                        33\n",
      "Orson Scott Card                      33\n",
      "Piers Anthony                         31\n",
      "Name: bookId, dtype: int64\n",
      "Authors with most ratings: \n",
      " author\n",
      "Agatha Christie                       68\n",
      "Terry Pratchett                       43\n",
      "Nora Roberts (Goodreads Author)       41\n",
      "Stephen King (Goodreads Author)       40\n",
      "Enid Blyton                           40\n",
      "Karen Kingsbury (Goodreads Author)    36\n",
      "Dean Koontz (Goodreads Author)        36\n",
      "P.G. Wodehouse                        33\n",
      "Orson Scott Card                      33\n",
      "Piers Anthony                         31\n",
      "Name: numRatings, dtype: int64\n",
      "Most popular languages: \n",
      " language\n",
      "English       24057\n",
      "Spanish         390\n",
      "French          356\n",
      "Arabic          348\n",
      "German          280\n",
      "Portuguese      228\n",
      "Italian         169\n",
      "Dutch           126\n",
      "Turkish         116\n",
      "Indonesian      115\n",
      "Name: bookId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2) Ποιά είναι τα 10 βιβλία με τις περισσότερες σελίδες.\n",
    "sorted_by_pages = df_clean.sort_values('pages', key=lambda x: x)\n",
    "print(\"Books with most pages: \\n\", sorted_by_pages['bookId'][:10])\n",
    "\n",
    "# 3) Ποιά είναι τα 10 βιβλία με τις περισσότερες σελίδες.\n",
    "sorted_by_rating = df_clean.sort_values('ratingStar5', key=lambda x: x)\n",
    "print(\"Books with most 5 star ratings: \\n\", sorted_by_rating['bookId'][:10])\n",
    "\n",
    "# 5) Ποιοι είναι οι 10 συγγραφεις με τα περισσότερα βιβλία\n",
    "grouped_by_author = df_clean.groupby(['author']).count()\n",
    "sorted_by_author_books = grouped_by_author.sort_values(['bookId'], key=lambda x: x,ascending=False)\n",
    "print(\"Authors with most books: \\n\", sorted_by_author_books['bookId'][:10])\n",
    "\n",
    "# 6) Ποιοι είναι οι 10 συγγραφείς με τις περισσότερες κριτικές\n",
    "sorted_by_author_ratings = grouped_by_author.sort_values(['numRatings'], key=lambda x: x,ascending=False)\n",
    "print(\"Authors with most ratings: \\n\", sorted_by_author_ratings['numRatings'][:10])\n",
    "\n",
    "# 8) Ποιές είναι οι πιο συχνές γλώσσες που έχουν γραφτεί τα βιβλία\n",
    "grouped_by_language = df_clean.groupby('language')['bookId'].count()\n",
    "sorted_by_language = grouped_by_language.sort_values(ascending=False)\n",
    "print(\"Most popular languages: \\n\", sorted_by_language[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d429d8e",
   "metadata": {
    "id": "0d429d8e"
   },
   "source": [
    "## 3) Υλοποίηση Recommendation system (35%)\n",
    "Ο στόχος ενός τέτοιου συστήματος είναι (1) να προβλέψει τις αξιολογήσεις ενός χρήστη για τα\n",
    "βιβλία που δεν έχει διαβάσει ακόμα, και (2) να εμφανίσει ένα ταξινομημένη λίστα με τα κορυφαία\n",
    "Ν βιβλία για τα οποία πιστεύουμε ότι θα ήθελαν να μάθουν περισσότερα. ‘Ενας άλλος στόχος\n",
    "ενός Recommender είναι (3) να βοηθήσει τους χρήστες να ανακαλύψουν σχετικά βιβλία που δεν\n",
    "θα είχαν βρει διαφορετικά.\n",
    "Σε αυτό το ερώτημα θα χρειαστείτε τις στήλες\n",
    "* BookId\n",
    "* Description\n",
    "* Και μόνο όσες γραμμές έχουν γλώσσα “English”. \n",
    "\n",
    "Δημιουργήστε τον TF-IDF (Term Frequency - Inverse Document Frequency) πίνακα των\n",
    "unigrams και των bigrams για τη στήλη description (χρησιμοποιήστε την παράμετρο stop_word\n",
    "του TfidfVectorizer).\n",
    "\n",
    "**Cosine Similarity**: Η μετρική αυτή υπολογίζει την ομοιότητα μεταξύ δύο διανυσμάτων x,y,\n",
    "χρησιμοποιώντας τη γωνία μεταξύ τους (όταν η γωνία είναι 0 σημαίνει ότι τα x και y είναι ίσα , αν\n",
    "εξαιρέσουμε το μήκος τους). Διατρέξτε τον TF-IDF πίνακα και υπολογίστε το similarity καθενός\n",
    "βιβλίου με τα υπόλοιπα. Αποθηκεύστε σε ένα python dictionary τα 100 πιο όμοια βιβλία.\n",
    "\n",
    "Πρόβλεψη: Φτιάξτε μία συνάρτηση η οποία παίρνει σαν είσοδο ένα id και ένα ακέραιο αριθμό N,\n",
    "και επιστρέφει τα Ν πιο όμοια βιβλία.\n",
    "recommend(item_id = 4085439, num = 5)\n",
    "\n",
    "Η έξοδος της συνάρτησης να είναι της παρακάτω μορφής μορφής:\n",
    "```\n",
    "Recommending 5 books similar to: The Hunger Games\n",
    "-------------------------------------------------\n",
    "Recommended: NAME\n",
    "Description: DESCRIPTION\n",
    "(score:0.12235188993161432)\n",
    "Recommended: NAME\n",
    "Description: DESCRIPTION\n",
    "(score:0.12235188993161432 \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123a21a3",
   "metadata": {
    "id": "123a21a3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Keep only the book Ids and their respective descriptions \n",
    "# ΤHN book_descriptions ΧΡΕΙΑΖΕΤΑΙ H recommend() function \n",
    "book_descriptions = df_clean.loc[ \n",
    "    (df_clean['language'] == 'English'),['bookId','description']].reset_index(drop=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    token_pattern = r'\\b(?![A-Za-z]\\b)[A-Za-z]+\\b', #ignore numbers and such\n",
    "    #min_df = 0.0014, # I exclude rare words, as they have little contribution to overarching theme of a book,might change it later\n",
    "    ngram_range=(1, 2), # unigrams and bigrams\n",
    "    strip_accents='unicode', # probably won't need that since we are only in English but you never know\n",
    "    stop_words='english', # ignore stop words \n",
    ")\n",
    "\n",
    "#rows = len(book_descriptions.index)\n",
    "\n",
    "matrix = vectorizer.fit_transform(book_descriptions['description'])\n",
    "similarities = cosine_similarity(matrix) # calculate the similarity matrix (735,735)\n",
    "np.fill_diagonal(similarities,-1) # remove the self similarities\n",
    "flat = similarities.flatten()\n",
    " \n",
    "# creating pairs with the 100 most similar books\n",
    "pairs = []\n",
    "for i in range(len(similarities)):\n",
    "    array = similarities[i].copy()\n",
    "    for j in range(100): # for 100 times\n",
    "        index = np.argmax(array) # get the largest remaining similarity in the flat matrix\n",
    "        pairs.append((i,index,array[index])) # save the similarity pair\n",
    "        array[index] = -1 # get remove it from the matrix so as to not find it again\n",
    "        \n",
    "dictionary = {}\n",
    "i = 0\n",
    "for (index1,index2,sim) in pairs:\n",
    "    dictionary[i] = (book_descriptions['bookId'][index1],book_descriptions['bookId'][index2],sim)\n",
    "    i = i+1\n",
    "\n",
    "def recommend(bookId, findNsimilar):\n",
    "    title = df_clean.loc[df_clean['bookId'] == bookId, 'title'].values[0]\n",
    "    print(\"Recommending 5 books similar to:\", title, \"\\n-------------------------------------------------\")\n",
    "    row = (book_descriptions[book_descriptions['bookId'] == bookId].index.tolist())[0]\n",
    "    for i in range(findNsimilar):\n",
    "        bookId = dictionary[row*100+i][1]\n",
    "        recommended_title = df_clean.loc[df_clean['bookId'] == bookId, 'title'].values[0]\n",
    "        recommended_description = df_clean.loc[df_clean['bookId'] == bookId, 'description'].values[0]\n",
    "        print(\"Recommended: \", recommended_title)\n",
    "        print(\"Description: \", recommended_description,\"\\n\")\n",
    "        print(\"(score:\", dictionary[row*100+i][2], \")\\n\")\n",
    "        \n",
    "recommend('591965.The_Madwoman_of_Chaillot', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2edc0",
   "metadata": {
    "id": "64f2edc0"
   },
   "source": [
    "## 4) Υλοποίηση Κατηγοριοποίησης (Classification) (35%)\n",
    "Χρησιμοποιήστε την στήλη genreSingle, βρείτε τα 10 πιο συχνά genres και κρατήστε σε ένα νέο\n",
    "dataframe τα βιβλία εκείνα που ανήκουν σε αυτες τις 10 πιο συχνές κατηγορίες. Θα χρειαστείτε\n",
    "το bookId το description και το genreSingle. Στην συνέχεια καθαρίστε την στήλη description\n",
    "χρησιμοποιώντας τις μεθόδους που είδαμε στα φροντιστήρια (πχ αφαίρεση σημείων στίξης,\n",
    "μετατροπή όλων των χαρακτήρων σε πεζά, κ.α.). Εφαρμόστε την μέθοδο word2vec για τα\n",
    "descriptions και στην συνέχεια με την χρήση των embeddings να υπολογίσετε για κάθε\n",
    "description ένα διάνυσμα με 200-300 τιμές (features) - αυτό θα είναι ο μέσος όρος των\n",
    "embeddings των λέξεων από τις οποίες αποτελείται το description.\n",
    "\n",
    "Χρησιμοποιήστε τη βιβλιοθήκη pickle της Python για να αποθηκεύσετε τα χαρακτηριστικά σε\n",
    "αρχεία *.pkl . Με αυτό τον τρόπο δεν χρειάζεται να υπολογίζονται από την αρχή τα\n",
    "χαρακτηριστικά κάθε φορά που τρέχετε το πρόγραμμά σας, αλλά μπορείτε μόνο να τα φορτωνεται\n",
    "στην μνήμη χρησιμοποιώντας την αντίστοιχη μέθοδο load.\n",
    "Χωρίστε το σύνολο των δεδομένων σε train (80%) και test (20%) χρησιμοποιώντας την μέθοδο\n",
    "train_test_split() της βιβλιοθήκης sklearn.\n",
    "\n",
    "Σε αυτό το ερώτημα θα πρέπει το πρόγραμμα σας να μπορεί να βρει τις κατηγορίες (genre) του\n",
    "συνόλου δοκιμής (test) χρησιμοποιώντας τις παρακάτω μεθόδους Classification:\n",
    "* Naive Bayes\n",
    "* Support Vector Machines (SVM, να πειραματιστείτε με τις παραμέτρους kernel (rbf, linear), c\n",
    "και gamma. H επιλογή των παραμέτρων μπορεί να γίνει και με GridSearchCV)\n",
    "* Random Forests\n",
    "\n",
    "Ολα τα παραπάνω μοντέλα θα εκπαιδευτούν MONO στο σύνολο train και θα αξιολογηθούν στο\n",
    "σύνολο test. Επίσης θα πρέπει να αξιολογήσετε και να καταγράψετε την απόδοση κάθε μεθόδου\n",
    "χρησιμοποιώντας 10-fold Cross Validation χρησιμοποιώντας τις παρακάτω μετρικές:\n",
    "* Precision / Recall / F-Measure\n",
    "* Accuracy\n",
    "\n",
    "Στο τέλος να ετοιμάσετε ένα πίνακα με τα αποτελέσματα των πειραμάτων σας για κάθε\n",
    "μετρική/παράμετρο που χρησιμοποιήσατε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2431a94e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "2431a94e",
    "outputId": "64e5e5c2-643d-4699-ba1f-5b755fb50e2c"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-b3a486289839>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    from  tensorflow.keras.preprocessing.text\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from  tensorflow.keras.preprocessing.text\n",
    "\n",
    "df_genre_counts = df_clean.groupby('genreSingle')[['bookId']].count()\n",
    "top_10 = df_genre_counts.sort_values(by='bookId', ascending=False)[:10]\n",
    "top_10_with_genre = top_10.reset_index()\n",
    "print(np.array(top_10_with_genre['genreSingle']))\n",
    "\n",
    "# DataFrame.drop(labels=None, *, axis=0, index=None, columns=None, \n",
    "#                level=None, inplace=False, errors='raise')\n",
    "\n",
    "new_df = df_clean.drop(df_clean[~df_clean['genreSingle'].isin(top_10_with_genre['genreSingle'])].index)\n",
    "new_df = new_df.loc[ \n",
    "    (new_df['language'] == 'English')].reset_index(drop=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english', # ignore stop words \n",
    ")\n",
    "\n",
    "clean_descriptions = []\n",
    "for description in new_df['description']:\n",
    "    vectorizer.fit(description.split('\\n'))\n",
    "    clean_descriptions.append(vectorizer.get_feature_names_out())\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
